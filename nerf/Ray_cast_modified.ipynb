{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray cast vizualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to check if rays are being cast correctly. Modified from original to avoid using trimesh; will work with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import open3d\n",
    "# import trimesh\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import enable_eager_execution\n",
    "enable_eager_execution()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 256\n",
      "(5, 256, 256, 4) (5, 4, 4) [35. 35. 35. 35. 35.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Loading\n",
    "\n",
    "data = np.load('/home/sushmitawarrier/clevr-dataset-gen/output/GPU_data_rsynced/CLEVR_new000000/images/CLEVR_new000000/lettuce_scene000000_transforms_4.npz')\n",
    "images = data['images']\n",
    "poses = data['poses']\n",
    "focal = data['focal']\n",
    "# verts = data['verts']\n",
    "H, W = images.shape[1:3]\n",
    "print(H, W)\n",
    "print(images.shape, poses.shape, focal)\n",
    "\n",
    "testimg, testpose = images[4], poses[4]\n",
    "images = images[:3,...,:3]\n",
    "poses = poses[:3]\n",
    "\n",
    "plt.imshow(testimg)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def face_process(face_list):\n",
    "\tfaces=list(map(lambda x:int(x.split(b'/')[0]),face_list[1:]))\n",
    "\treturn faces\n",
    "\n",
    "def load_obj(filename):\n",
    "\tf=open(filename,\"rb\")\n",
    "\tlines = f.readlines()\n",
    "\n",
    "\tverts=list(filter(lambda x:x[:2]==b\"v \", lines))\n",
    "\tfaces=list(filter(lambda x:x[:2]==b\"f \", lines))\n",
    "\n",
    "\tverts=list(map(lambda x:x.strip().split()[1:],verts))\n",
    "\tverts=np.array(verts).astype(\"float32\")\n",
    "\tfaces=list(map(lambda x:x.strip().split(),faces))\n",
    "\tfaces=list(map(face_process,faces))\n",
    "\tfaces=np.array(faces).astype(\"int32\")-1\n",
    "\n",
    "\treturn lines,verts, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls ../output/GPU_data_rsynced/CLEVR_new000000/objfiles\n",
    "\n",
    "lines, verts, faces = load_obj('../output/GPU_data_rsynced/CLEVR_new000000/objfiles/000004.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.load('/home/sushmitawarrier/clevr-dataset-gen/output/GPU_data_rsynced/CLEVR_new000000/images/CLEVR_new000000/lettuce_scene000000_transforms_4.npz')\n",
    "#images = data['images']\n",
    "#poses = data['poses']\n",
    "#focal = data['focal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogenize=np.ones((verts.shape[0],1))\n",
    "verts_h = np.concatenate([verts,homogenize],axis=1)\n",
    "\n",
    "verts_hc = verts_h.copy()\n",
    "#verts_hc[:,1] = verts_h[:,2]\n",
    "#verts_hc[:,2] = verts_h[:,0]\n",
    "#verts_hc[:,0] = verts_h[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.090254  ,  0.007464  ,  0.040401  ,  1.        ],\n",
       "       [ 0.51638901,  0.300156  ,  0.25070301,  1.        ],\n",
       "       [-0.115507  ,  0.01107   ,  0.037663  ,  1.        ],\n",
       "       ...,\n",
       "       [ 0.58562303,  1.349298  ,  0.038803  ,  1.        ],\n",
       "       [ 0.612221  ,  1.33343303, -0.090776  ,  1.        ],\n",
       "       [ 0.58890003,  1.30776596, -0.21443   ,  1.        ]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verts_hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-b21a5eb46a3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrot_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#rot_c[2] = -rot[2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "\n",
    "rot=poses[4][:3, :3]\n",
    "rot_c = rot.copy()\n",
    "#rot_c[2] = -rot[2]\n",
    "\n",
    "trans=poses[4][:3,3]\n",
    "trans_c = trans.copy()\n",
    "#trans_c[0]=trans[1]\n",
    "#trans_c[1]=trans[0]\n",
    "\n",
    "\n",
    "#projections=th.matmul(torch.from_numpy(verts).float(),torch.from_numpy(poses[1][:3,:3]).float())-torch.from_numpy(trans_c).float()\n",
    "projections=th.matmul(torch.from_numpy(verts_hc).float(),torch.from_numpy(poses[4]).T.float()) #-torch.from_numpy(trans_c).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'projections' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-2ffc593776f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprojections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfocal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#/(points[:,2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mfocal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#/(points[:,2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'projections' is not defined"
     ]
    }
   ],
   "source": [
    "points=projections\n",
    "y= focal[4]*points[:,1] #/(points[:,2])\n",
    "x= focal[4]*points[:,0] #/(points[:,2])\n",
    "plt.scatter(y,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-5899ea219614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'points' is not defined"
     ]
    }
   ],
   "source": [
    "points[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-a47444226446>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpoints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'points' is not defined"
     ]
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trans_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-ae046ba3c638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrans_c\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trans_c' is not defined"
     ]
    }
   ],
   "source": [
    "trans_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-4c2f107123c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 3"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(images[4][:,:,:3])\n",
    "plt.scatter(y,x-128)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-1d34c0830dc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "images[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "def pos_enc(a,L):\n",
    "    \n",
    "    x=[torch.sin(2.**i*a) for i in range(L)] + [torch.sin(2.**i*np.pi*a) for i in range(L)] + [a]\n",
    "    \n",
    "    return torch.cat(x,dim=0)\n",
    "\n",
    "\n",
    "class NeRF(nn.Module):\n",
    "    \n",
    "    def __init__(self,Lp):\n",
    "        super().__init__()\n",
    "        self.Lp = Lp\n",
    "        \n",
    "        module = []\n",
    "        \n",
    "        module.extend([nn.Linear(3*2*Lp+3,256),nn.ReLU()])\n",
    "        \n",
    "        # 7 layers\n",
    "        for i in range(7):\n",
    "            module.extend([nn.Linear(256,256),nn.ReLU()])\n",
    "        \n",
    "        module.extend([nn.Linear(256,4)])\n",
    "        self.nerf = nn.Sequential(*module)\n",
    "        \n",
    "        self.apply(lambda x: init_weights(x))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        inp = pos_enc(input,self.Lp)\n",
    "        print(\"inp before permute\", inp.shape)\n",
    "        inp = inp.permute(1, 0,2)\n",
    "        print(\"inp before reshape\", inp.shape)\n",
    "        inp = inp.reshape([inp.shape[0],-1])\n",
    "        print(\"inp shape\", inp.shape)\n",
    "        \n",
    "        rgba = self.nerf(inp)\n",
    "        return torch.sigmoid(rgba[:,:3]), torch.relu(rgba[:,3])\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 6250, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_enc(pw, 6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerf=NeRF(6)\n",
    "optim=torch.optim.Adam(nerf.parameters(),0.001,(0.9,0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Tf compares\n",
    "def get_rays(H, W, focal, c2w):\n",
    "    i, j = tf.meshgrid(tf.range(W, dtype=tf.float32), tf.range(H, dtype=tf.float32), indexing='xy')\n",
    "    dirs = tf.stack([(i*10-50)/focal, -(j*10-50)/focal, -tf.ones_like(i)], -1)\n",
    "    rays_d = tf.reduce_sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)\n",
    "    rays_o = tf.broadcast_to(c2w[:3,-1], tf.shape(rays_d))\n",
    "    return rays_o.numpy(), rays_d.numpy(), dirs.numpy()\n",
    "rays_o, rays_d, dirs = get_rays(H/10,W/10, focal[0], poses[0])\n",
    "\n",
    "##\n",
    "c2w=torch.from_numpy(poses[0])\n",
    "#gur=th.bmm(p,c2w[:3,:3].T.view(1,3,3))\n",
    "\n",
    "##\n",
    "rays_o, rays_d\n",
    "N_samples = 10\n",
    "z_vals = tf.linspace(5.0, 8.0, N_samples)\n",
    "z_vals += tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (8.0-5.0)/N_samples\n",
    "#pts = rays_o[...,None,:] + rays_d[...,None,:] * z_vals[...,:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "def cast_rays(H, W, focal, scale, c2w, ns):\n",
    "    \n",
    "    nx = H // scale\n",
    "    ny = W // scale\n",
    "    #ns = nb_samples\n",
    "    \n",
    "    \n",
    "    # Sample front plane\n",
    "    yy,xx = torch.meshgrid(torch.linspace(0,ny-1,ny),torch.linspace(0,nx-1,nx))\n",
    "    # scaling factor\n",
    "    o = torch.Tensor(1,nx*ny,1).fill_(1)\n",
    "    \n",
    "    ix = xx.reshape(1,-1)*scale\n",
    "    iy = yy.reshape(1,-1)*scale\n",
    "    points = th.cat([(ix.unsqueeze(-1)-W/2)/focal, -(iy.unsqueeze(-1)-H/2)/focal, -o], dim=-1)\n",
    "    \n",
    "    camtrans = -torch.matmul(c2w[:3,-1],c2w[:3,:3])\n",
    "    near_distance = camtrans\n",
    "    far_distance = camtrans+5\n",
    "    \n",
    "    t=torch.linspace(0,1,ns)\n",
    "    # add jitter to sampling direction, so we get non-uniform samples\n",
    "    t_noisy = t.view(1,ns,1,1) + torch.Tensor(1,ns,nx*ny,1).uniform_(0,1)/ns\n",
    "    \n",
    "    t_scale = t_noisy*far_distance + (1-t_noisy)*near_distance\n",
    "    points_move = t_scale * points.view(1,1,nx*ny,3)\n",
    "    \n",
    "    points_world = th.bmm((points_move).view(1,-1,3),c2w[:3,:3].T.view(1,3,3)) \n",
    "    \n",
    "    return points, points_move.view(1,-1,3), points_world\n",
    "\n",
    "def raytrace(z,sigma_a,rgb):\n",
    "    dists = th.cat([z[..., 1:,:] - z[..., :-1,:], th.ones_like(z[...,:1,:]).fill_(1e10)], -1) \n",
    "    alpha = 1.-th.exp(-sigma_a * dists)  \n",
    "    weights = alpha * th.cumprod(1.-alpha + 1e-10, -1, exclusive=True)\n",
    "    \n",
    "    rgb_map = (weights[...,None] * rgb).sum(dim=-2) \n",
    "    depth_map =(weights * z_vals).sum(dim=-1)\n",
    "    acc_map = weights.sum(dim=-1)\n",
    "\n",
    "    return rgb_map, depth_map, acc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-3.6571,  3.6571, -1.0000],\n",
       "          [-3.3714,  3.6571, -1.0000],\n",
       "          [-3.0857,  3.6571, -1.0000],\n",
       "          ...,\n",
       "          [ 2.6286, -3.2000, -1.0000],\n",
       "          [ 2.9143, -3.2000, -1.0000],\n",
       "          [ 3.2000, -3.2000, -1.0000]]]),\n",
       " tensor([[[ -0.2253,   0.2253,   9.8539],\n",
       "          [ -0.1546,   0.1677,   9.8696],\n",
       "          [ -0.1674,   0.1985,   9.8612],\n",
       "          ...,\n",
       "          [ 13.1837, -16.0497,   4.9000],\n",
       "          [ 14.6469, -16.0829,   4.8896],\n",
       "          [ 16.1339, -16.1339,   4.8736]]], dtype=torch.float64),\n",
       " tensor([[[  9.5764,   2.3328,   0.2253],\n",
       "          [  9.5733,   2.4051,   0.1677],\n",
       "          [  9.5685,   2.3905,   0.1985],\n",
       "          ...,\n",
       "          [  1.3208,  14.0026, -16.0497],\n",
       "          [  0.9321,  15.4133, -16.0829],\n",
       "          [  0.5318,  16.8455, -16.1339]]], dtype=torch.float64))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cast_rays(H,W,focal[0],10,torch.from_numpy(poses[img_i]),64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,pm,pw=cast_rays(H,W,focal[0],10,torch.from_numpy(poses[img_i]),10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagert shape torch.Size([1, 256, 256, 3])\n",
      "torch.Size([1, 6250, 3])\n",
      "inp before permute torch.Size([13, 6250, 3])\n",
      "inp before reshape torch.Size([6250, 13, 3])\n",
      "inp shape torch.Size([6250, 39])\n",
      "rgb shape torch.Size([6250, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (6250) must match the size of tensor b (256) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-483256c2f911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rgb shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (6250) must match the size of tensor b (256) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "N_samples = 64\n",
    "N_iters = 1000\n",
    "psnrs = []\n",
    "iternums = []\n",
    "i_plot = 25\n",
    "\n",
    "import time\n",
    "t = time.time()\n",
    "for i in range(N_iters+1):\n",
    "    \n",
    "    img_i = np.random.randint(images.shape[0])\n",
    "    target = torch.from_numpy(images[img_i]).unsqueeze(0)\n",
    "    print(\"tagert shape\", target.shape)\n",
    "    pose = torch.from_numpy(poses[img_i]).unsqueeze(0)\n",
    "    p,pm,pw=cast_rays(H,W,focal[0],10,torch.from_numpy(poses[img_i]),10)\n",
    "    print(pw.shape)\n",
    "    \n",
    "    rgb,alpha=nerf(pw.float()) #.type(torch.FloatTensor))\n",
    "    print(\"rgb shape\", rgb.shape)\n",
    "    \n",
    "    loss = th.mean((rgb - target).pow(2))\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    if i%i_plot==0:\n",
    "        print(i, (time.time() - t) / i_plot, 'secs per iter')\n",
    "        t = time.time()\n",
    "        \n",
    "        # Render the holdout view for logging\n",
    "        rays_o, rays_d = get_rays(H, W, focal[0], testpose)\n",
    "        rgb, depth, acc = render_rays(model, rays_o, rays_d, near=2., far=6., N_samples=N_samples)\n",
    "        loss = tf.reduce_mean(tf.square(rgb - testimg))\n",
    "        psnr = -10. * tf.math.log(loss) / tf.math.log(10.)\n",
    "\n",
    "        psnrs.append(psnr.numpy())\n",
    "        iternums.append(i)\n",
    "        \n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(rgb)\n",
    "        plt.title(f'Iteration: {i}')\n",
    "        plt.subplot(122)\n",
    "        plt.plot(iternums, psnrs)\n",
    "        plt.title('PSNR')\n",
    "        plt.show()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d\n",
    "\n",
    "p,pm,pw=cast_rays(H,W,focal[0],10,torch.from_numpy(poses[0]),10)\n",
    "p,pm,pw_2=cast_rays(H,W,focal[0],10,torch.from_numpy(poses[2]),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have replaced this with values from the .npz file\n",
    "# mesh=trimesh.load('./mesh.obj')\n",
    "# verts=np.array(mesh.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'open3d' has no attribute 'JVisualizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-08982923d91e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Point clouds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mviz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpcd1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPointCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpcd1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVector3dVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'open3d' has no attribute 'JVisualizer'"
     ]
    }
   ],
   "source": [
    "# Point clouds\n",
    "viz=open3d.JVisualizer()\n",
    "\n",
    "pcd1 = open3d.geometry.PointCloud()\n",
    "pcd1.points = open3d.utility.Vector3dVector(p[0].numpy())\n",
    "pcd1.paint_uniform_color(np.array([1,0,0],dtype=np.float32))\n",
    "\n",
    "pcd2 = open3d.geometry.PointCloud()\n",
    "pcd2.points = open3d.utility.Vector3dVector(pm[0].numpy())\n",
    "pcd2.paint_uniform_color(np.array([0,1,0],dtype=np.float32))\n",
    "\n",
    "pcd3 = open3d.geometry.PointCloud()\n",
    "pcd3.points = open3d.utility.Vector3dVector(pw[0].numpy())\n",
    "pcd3.paint_uniform_color(np.array([0,0,1],dtype=np.float32))\n",
    "\n",
    "# pcd4 = open3d.geometry.PointCloud()\n",
    "# pcd4.points = open3d.utility.Vector3dVector(pw_2[0].numpy())\n",
    "# pcd4.paint_uniform_color(np.array([1,0,1],dtype=np.float32))\n",
    "\n",
    "pcd5=open3d.geometry.PointCloud()\n",
    "pcd5.points = open3d.utility.Vector3dVector(verts)\n",
    "pcd5=pcd5.uniform_down_sample(100)\n",
    "pcd5.paint_uniform_color(np.array([0,1,1],dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz=open3d.JVisualizer()\n",
    "\n",
    "viz.add_geometry(pcd5)\n",
    "viz.add_geometry(pcd1)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz=open3d.JVisualizer()\n",
    "\n",
    "viz.add_geometry(pcd5)\n",
    "viz.add_geometry(pcd2)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz=open3d.JVisualizer()\n",
    "\n",
    "viz.add_geometry(pcd5)\n",
    "viz.add_geometry(pcd3)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0])\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz=open3d.JVisualizer()\n",
    "\n",
    "viz.add_geometry(pcd5)\n",
    "viz.add_geometry(pcd3)\n",
    "viz.add_geometry(pcd4)\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd5 = open3d.geometry.PointCloud()\n",
    "pcd5.points = open3d.utility.Vector3dVector(pws[0].numpy())\n",
    "pcd5.paint_uniform_color(np.array([1,0,1],dtype=np.float32))\n",
    "\n",
    "pcd6 = open3d.geometry.PointCloud()\n",
    "pcd6.points = open3d.utility.Vector3dVector(pts_tp)\n",
    "pcd6.paint_uniform_color(np.array([1,1,0],dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pws=pw.clamp(-1.5,1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#viz.add_geometry(pcd3)\n",
    "viz=open3d.JVisualizer()\n",
    "\n",
    "viz.add_geometry(pcd5)\n",
    "#viz.add_geometry(pcd6)\n",
    "viz.add_geometry(pcd4)\n",
    "viz.show()\n",
    "del viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh=trimesh.load('./mesh.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=np.array(mesh.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g[:,0]=g[:,0]\n",
    "g[:,1]=g[:,1]\n",
    "g[:,2]=-g[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd4=open3d.geometry.PointCloud()\n",
    "pcd4.points = open3d.utility.Vector3dVector(k)\n",
    "pcd4=pcd4.uniform_down_sample(100)\n",
    "pcd4.paint_uniform_color(np.array([0,0,1],dtype=np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd5=open3d.geometry.PointCloud()\n",
    "pcd5.points = open3d.utility.Vector3dVector(points[0].numpy())\n",
    "pcd5=pcd5.uniform_down_sample(100)\n",
    "pcd5.paint_uniform_color(np.array([1,1,1],dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=g[:,(1,0,2)]\n",
    "l=th.from_numpy(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm=th.cat([l.float().unsqueeze(0),torch.ones_like(l).float().unsqueeze(0)],dim=-1)\n",
    "lm=lm[:,:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2w=torch.from_numpy(poses[2])\n",
    "points=th.bmm(l.float().unsqueeze(0),c2w[:3,:3].unsqueeze(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=l[:,:2]\n",
    "pts=z*focal[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[2])\n",
    "plt.scatter(pts[:,0]+50,pts[:,1]+50,alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VolRend",
   "language": "python",
   "name": "volrend"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
